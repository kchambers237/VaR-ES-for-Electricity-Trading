{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15982139",
   "metadata": {},
   "source": [
    "# Electricity portfolio VaR & ES framework with real exposures and EWMA covariance.\n",
    "\n",
    "Core features:\n",
    "- Reads market data from Excel:\n",
    "    - prices.xlsx: wide format, index = Date, columns = product names, values = prices\n",
    "    - positions.xlsx: columns = [\"Product\", \"MWh\", \"Sensitivity\"]\n",
    "- Computes:\n",
    "    - Historical VaR & ES\n",
    "    - Parametric VaR & ES using EWMA covariance \n",
    "    - Monte Carlo VaR & ES using EWMA covariance\n",
    "    - Backtesting (Kupiec POF, Christoffersen independence)\n",
    "    - Volatility and correlation stress tests\n",
    "- Builds a Plotly dashboard:\n",
    "    - Row 1: Histograms with VaR & ES lines (Historical, Parametric, Monte Carlo)\n",
    "    - Row 2: Enhanced exposure weights plot (sorted, top-5 highlight, category colors, Pareto curve)\n",
    "    - Row 3: Metrics table\n",
    "- Logs all key metrics and exposure weights to an Excel file (risk_results.xlsx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33032da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm, chi2\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "# Configuration\n",
    "\n",
    "with open(\"config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "    \n",
    "alpha = config[\"alpha\"]                 # VaR / ES confidence level\n",
    "n_days = config[\"n_days\"]               # Number of historical days (synthetic)\n",
    "n_mc = config[\"n_mc\"]                   # Monte Carlo scenarios\n",
    "kpi_filename = config[\"KPI_filename\"]\n",
    "dashboard_name = config[\"dashboard_name\"]\n",
    "ewma_lambda = config[\"ewma_lambda\"]     \n",
    "k = config[\"volatility_stress_factor\"] \n",
    "delta_rho = config[\"correlation_stress_factor\"] \n",
    "\n",
    "prices_xlsx = \"prices.xlsx\"   \n",
    "positions_xlsx = \"positions.xlsx\"  \n",
    "\n",
    "\n",
    "# Instrument and Portfolio Classes\n",
    "class Instrument:\n",
    "    \"\"\"\n",
    "    Represents a single electricity trading instrument with real exposure.\n",
    "    Attributes:\n",
    "    - name: product identifier (e.g. \"MBL_1\", \"MPL_3\", etc.)\n",
    "    - prices: time series of prices (pd.Series indexed by Date)\n",
    "    - mwh: position size in MWh\n",
    "    - price_sensitivity: delta with respect to price \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name: str, prices: pd.Series, mwh: float, price_sensitivity: float):\n",
    "        self.name = name\n",
    "        self.prices = prices\n",
    "        self.mwh = mwh\n",
    "        self.price_sensitivity = price_sensitivity\n",
    "\n",
    "    @property\n",
    "    def returns(self) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Compute log-returns of the instrument:\n",
    "            r_t = ln(P_t / P_{t-1})\n",
    "        Returns:\n",
    "            pd.Series of log-returns, aligned with the price index (minus first observation).\n",
    "        \"\"\"\n",
    "        return np.log(self.prices / self.prices.shift(1)).dropna()\n",
    "\n",
    "    @property\n",
    "    def exposure(self) -> float:\n",
    "        \"\"\"\n",
    "        Compute the instrument's exposure using the latest available price:\n",
    "            Exposure_i = Price_i * MWh_i * price_sensitivity_i\n",
    "        Returns:\n",
    "            float: exposure value.\n",
    "        \"\"\"\n",
    "        latest_price = self.prices.iloc[-1]\n",
    "        return float(latest_price * self.mwh * self.price_sensitivity)\n",
    "\n",
    "\n",
    "class Portfolio:\n",
    "    \"\"\"\n",
    "    Represents a portfolio of electricity instruments.\n",
    "    Provides:\n",
    "    - Aligned returns matrix for all instruments\n",
    "    - Exposure vector\n",
    "    - Portfolio return and loss series\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, instruments: list[Instrument]):\n",
    "        self.instruments = instruments\n",
    "\n",
    "    def get_returns_matrix(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Build a DataFrame of instrument returns aligned by date.\n",
    "        Returns:\n",
    "            pd.DataFrame: columns = instrument names, index = dates, values = returns.\n",
    "        \"\"\"\n",
    "        rets = {inst.name: inst.returns for inst in self.instruments}\n",
    "        df = pd.DataFrame(rets).dropna()\n",
    "        return df\n",
    "\n",
    "    def get_exposure_vector(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Build the exposure vector from all instruments.\n",
    "        Returns:\n",
    "            np.ndarray: exposures for each instrument in the portfolio.\n",
    "        \"\"\"\n",
    "        return np.array([inst.exposure for inst in self.instruments], dtype=float)\n",
    "\n",
    "    def portfolio_return_series(self) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Compute the portfolio return series as a weighted sum of instrument returns:\n",
    "            R_{P,t} = sum_i w_i * r_{i,t}\n",
    "        where:\n",
    "            w_i = Exposure_i / sum_j |Exposure_j|\n",
    "        Returns:\n",
    "            pd.Series: portfolio returns over time.\n",
    "        \"\"\"\n",
    "        returns_df = self.get_returns_matrix()\n",
    "        exposures = self.get_exposure_vector()\n",
    "        # Normalize exposures by total absolute exposure to get weights\n",
    "        w_norm = exposures / np.sum(np.abs(exposures))\n",
    "        rp = returns_df.dot(w_norm)\n",
    "        rp.name = \"Portfolio_Return\"\n",
    "        return rp\n",
    "\n",
    "    def portfolio_loss_series(self) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Compute the portfolio loss series:\n",
    "            L_t = - R_{P,t}\n",
    "        Returns:\n",
    "            pd.Series: portfolio losses over time.\n",
    "        \"\"\"\n",
    "        rp = self.portfolio_return_series()\n",
    "        loss = -rp\n",
    "        loss.name = \"Portfolio_Loss\"\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da23d68",
   "metadata": {},
   "source": [
    "# EWMA Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9162880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ewma_covariance(returns_df: pd.DataFrame, lambda_: float = ewma_lambda) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute the EWMA covariance matrix.\n",
    "    Recursion:\n",
    "        Σ_t = λ Σ_{t-1} + (1 - λ) r_t r_t^T\n",
    "    where:\n",
    "        - λ is the decay factor (0 < λ < 1)\n",
    "        - r_t is the vector of returns at time t\n",
    "    Args:\n",
    "        returns_df: DataFrame of returns (rows = time, columns = instruments)\n",
    "        lambda_: EWMA decay factor\n",
    "    Returns:\n",
    "        np.ndarray: EWMA covariance matrix.\n",
    "    \"\"\"\n",
    "    # Convert to numpy array: shape (n_observations, n_instruments)\n",
    "    r = returns_df.values\n",
    "    n, k = r.shape\n",
    "    # Initialize with the sample covariance matrix\n",
    "    sigma = np.cov(r, rowvar=False)\n",
    "    # Recursively update the covariance matrix\n",
    "    for t in range(1, n):\n",
    "        rt = r[t].reshape(-1, 1)  # column vector\n",
    "        sigma = lambda_ * sigma + (1 - lambda_) * (rt @ rt.T)\n",
    "\n",
    "    return sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fccc808",
   "metadata": {},
   "source": [
    "# VaR & ES Calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4ce5359",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VaRCalculator:\n",
    "    \"\"\"\n",
    "    Computes Historical, Parametric, and Monte Carlo VaR & ES for the portfolio.\n",
    "\n",
    "    Uses:\n",
    "    - Historical VaR/ES directly from the loss distribution.\n",
    "    - Parametric VaR/ES using EWMA covariance and normality assumption.\n",
    "    - Monte Carlo VaR/ES using EWMA covariance and simulated returns.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, portfolio: Portfolio, alpha: float = alpha):\n",
    "        self.portfolio = portfolio\n",
    "        self.alpha = alpha\n",
    "        # Returns matrix and loss series are computed once and reused\n",
    "        self.returns_df = portfolio.get_returns_matrix()\n",
    "        self.loss_series = portfolio.portfolio_loss_series()\n",
    "\n",
    "    # Historical VaR & ES \n",
    "    def historical_var(self) -> float:\n",
    "        \"\"\"\n",
    "        Historical VaR at confidence level alpha:\n",
    "            VaR_alpha = quantile_alpha(Losses)\n",
    "        Returns:\n",
    "            float: historical VaR.\n",
    "        \"\"\"\n",
    "        return np.quantile(self.loss_series.values, self.alpha)\n",
    "\n",
    "    def historical_es(self) -> float:\n",
    "        \"\"\"\n",
    "        Historical Expected Shortfall (ES) at confidence level alpha:\n",
    "            ES_alpha = E[Loss | Loss >= VaR_alpha]\n",
    "        Returns:\n",
    "            float: historical ES.\n",
    "        \"\"\"\n",
    "        var = self.historical_var()\n",
    "        tail_losses = self.loss_series[self.loss_series >= var]\n",
    "        return tail_losses.mean()\n",
    "\n",
    "\n",
    "    # Parametric VaR & ES (EWMA) \n",
    "    def parametric_inputs(self):\n",
    "        \"\"\"\n",
    "        Compute parametric inputs based on EWMA covariance:\n",
    "        - mu_vec: vector of mean returns per instrument\n",
    "        - sigma_mat: EWMA covariance matrix\n",
    "        - mu_p: portfolio mean return\n",
    "        - sigma_p: portfolio volatility\n",
    "        - w_norm: normalized exposure-based weights\n",
    "        Returns:\n",
    "            (mu_vec, sigma_mat, mu_p, sigma_p, w_norm)\n",
    "        \"\"\"\n",
    "        rets = self.returns_df\n",
    "        mu_vec = rets.mean().values\n",
    "        sigma_mat = ewma_covariance(rets, lambda_=ewma_lambda)\n",
    "        exposures = self.portfolio.get_exposure_vector()\n",
    "        w_norm = exposures / np.sum(np.abs(exposures))\n",
    "\n",
    "        # Portfolio mean and variance\n",
    "        mu_p = w_norm @ mu_vec\n",
    "        sigma_p2 = w_norm @ sigma_mat @ w_norm\n",
    "        sigma_p = np.sqrt(sigma_p2)\n",
    "\n",
    "        return mu_vec, sigma_mat, mu_p, sigma_p, w_norm\n",
    "\n",
    "    def parametric_var(self) -> float:\n",
    "        \"\"\"\n",
    "        Parametric VaR under normality assumption:\n",
    "\n",
    "            VaR_alpha = - (μ_p + σ_p * z_alpha)\n",
    "\n",
    "        where z_alpha is the alpha-quantile of the standard normal distribution.\n",
    "\n",
    "        Returns:\n",
    "            float: parametric VaR.\n",
    "        \"\"\"\n",
    "        _, _, mu_p, sigma_p, _ = self.parametric_inputs()\n",
    "        z = norm.ppf(self.alpha)\n",
    "        var = -(mu_p + sigma_p * z)\n",
    "        return var\n",
    "\n",
    "    def parametric_es(self) -> float:\n",
    "        \"\"\"\n",
    "        Parametric ES under normality assumption:\n",
    "\n",
    "            ES_alpha = - ( μ_p - σ_p * φ(z_alpha) / (1 - α) )\n",
    "\n",
    "        where:\n",
    "            - φ is the standard normal pdf\n",
    "            - z_alpha is the alpha-quantile of the standard normal distribution.\n",
    "\n",
    "        Returns:\n",
    "            float: parametric ES.\n",
    "        \"\"\"\n",
    "        _, _, mu_p, sigma_p, _ = self.parametric_inputs()\n",
    "        z = norm.ppf(self.alpha)\n",
    "        phi_z = norm.pdf(z)\n",
    "        es = -(mu_p - sigma_p * phi_z / (1 - self.alpha))\n",
    "        return es\n",
    "\n",
    "    # ---------------- Monte Carlo VaR & ES (EWMA) ----------------\n",
    "\n",
    "    def monte_carlo_var_es(self, n_scenarios: int = n_mc):\n",
    "        \"\"\"\n",
    "        Monte Carlo VaR & ES using EWMA covariance:\n",
    "\n",
    "        Steps:\n",
    "        1. Estimate mean vector and EWMA covariance matrix.\n",
    "        2. Simulate multivariate normal returns.\n",
    "        3. Compute portfolio returns and losses.\n",
    "        4. Compute VaR and ES from simulated loss distribution.\n",
    "\n",
    "        Args:\n",
    "            n_scenarios: number of Monte Carlo scenarios.\n",
    "\n",
    "        Returns:\n",
    "            (var_mc, es_mc, sim_losses)\n",
    "        \"\"\"\n",
    "        rets = self.returns_df\n",
    "        mu_vec = rets.mean().values\n",
    "        sigma_mat = ewma_covariance(rets, lambda_= ewma_lambda)\n",
    "        exposures = self.portfolio.get_exposure_vector()\n",
    "        w_norm = exposures / np.sum(np.abs(exposures))\n",
    "\n",
    "        # Simulate multivariate normal returns\n",
    "        sim_rets = np.random.multivariate_normal(mu_vec, sigma_mat, size=n_scenarios)\n",
    "        # Portfolio returns from simulated scenarios\n",
    "        sim_port_rets = sim_rets @ w_norm\n",
    "        # Losses are negative returns\n",
    "        sim_losses = -sim_port_rets\n",
    "\n",
    "        # Monte Carlo VaR and ES\n",
    "        var_mc = np.quantile(sim_losses, self.alpha)\n",
    "        es_mc = sim_losses[sim_losses >= var_mc].mean()\n",
    "\n",
    "        return var_mc, es_mc, sim_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed25a09",
   "metadata": {},
   "source": [
    "# Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bc000b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Backtester:\n",
    "    \"\"\"\n",
    "    Implements:\n",
    "    - Kupiec Proportion of Failures (POF) test\n",
    "    - Christoffersen independence test\n",
    "\n",
    "    Uses a binary exceedance indicator:\n",
    "        I_t = 1 if Loss_t > VaR_t, else 0\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, loss_series: pd.Series, var_series: pd.Series, alpha: float = alpha):\n",
    "        self.loss_series = loss_series\n",
    "        self.var_series = var_series\n",
    "        self.alpha = alpha\n",
    "        self.indicator = self._exceedance_indicator()\n",
    "\n",
    "    def _exceedance_indicator(self) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Build the exceedance indicator series:\n",
    "\n",
    "            I_t = 1 if Loss_t > VaR_t, else 0\n",
    "\n",
    "        Returns:\n",
    "            pd.Series: indicator of VaR breaches.\n",
    "        \"\"\"\n",
    "        ind = (self.loss_series > self.var_series).astype(int)\n",
    "        ind.name = \"Exceedance_Indicator\"\n",
    "        return ind\n",
    "\n",
    "    def kupiec_pof_test(self):\n",
    "        \"\"\"\n",
    "        Kupiec Proportion of Failures (POF) test.\n",
    "\n",
    "        Tests whether the observed exceedance frequency matches the expected\n",
    "        frequency under the model (1 - alpha).\n",
    "\n",
    "        Returns:\n",
    "            (LR_pof, p_value, N, T)\n",
    "            - LR_pof: likelihood ratio statistic\n",
    "            - p_value: p-value under chi-square(1)\n",
    "            - N: number of exceedances\n",
    "            - T: total number of observations\n",
    "        \"\"\"\n",
    "        I = self.indicator\n",
    "        T = len(I)\n",
    "        N = I.sum()\n",
    "        p_hat = N / T\n",
    "        p0 = 1 - self.alpha\n",
    "\n",
    "        if p_hat in [0, 1]:\n",
    "            # Edge case: no variability in exceedances\n",
    "            LR_pof = 0.0\n",
    "        else:\n",
    "            # Likelihood under null (p0) and alternative (p_hat)\n",
    "            L0 = (p0 ** N) * ((1 - p0) ** (T - N))\n",
    "            L1 = (p_hat ** N) * ((1 - p_hat) ** (T - N))\n",
    "            LR_pof = -2 * np.log(L0 / L1)\n",
    "\n",
    "        p_value = 1 - chi2.cdf(LR_pof, df=1)\n",
    "        return LR_pof, p_value, N, T\n",
    "\n",
    "    def christoffersen_independence_test(self):\n",
    "        \"\"\"\n",
    "        Christoffersen independence test.\n",
    "\n",
    "        Tests whether exceedances are independent over time by looking at\n",
    "        the transition counts between states (0 -> 0, 0 -> 1, 1 -> 0, 1 -> 1).\n",
    "\n",
    "        Returns:\n",
    "            (LR_ind, p_value, (n00, n01, n10, n11))\n",
    "        \"\"\"\n",
    "        I = self.indicator.values\n",
    "        n00 = n01 = n10 = n11 = 0\n",
    "\n",
    "        # Count transitions between consecutive days\n",
    "        for t in range(1, len(I)):\n",
    "            prev, curr = I[t-1], I[t]\n",
    "            if prev == 0 and curr == 0:\n",
    "                n00 += 1\n",
    "            elif prev == 0 and curr == 1:\n",
    "                n01 += 1\n",
    "            elif prev == 1 and curr == 0:\n",
    "                n10 += 1\n",
    "            elif prev == 1 and curr == 1:\n",
    "                n11 += 1\n",
    "\n",
    "        n0 = n00 + n01\n",
    "        n1 = n10 + n11\n",
    "\n",
    "        # Conditional probabilities\n",
    "        pi01 = n01 / n0 if n0 > 0 else 0.0\n",
    "        pi11 = n11 / n1 if n1 > 0 else 0.0\n",
    "\n",
    "        N = I.sum()\n",
    "        T = len(I)\n",
    "        pi = N / T if T > 0 else 0.0\n",
    "\n",
    "        def safe_pow(base, exp):\n",
    "            # Avoid numerical issues when base <= 0\n",
    "            return base ** exp if base > 0 else 1.0\n",
    "\n",
    "        # Likelihood under null (independent with probability pi)\n",
    "        L0 = safe_pow(1 - pi, n00 + n10) * safe_pow(pi, n01 + n11)\n",
    "        # Likelihood under alternative (different probabilities after 0 and 1)\n",
    "        L1 = (safe_pow(1 - pi01, n00) * safe_pow(pi01, n01) *\n",
    "              safe_pow(1 - pi11, n10) * safe_pow(pi11, n11))\n",
    "\n",
    "        if L0 == 0 or L1 == 0:\n",
    "            LR_ind = 0.0\n",
    "        else:\n",
    "            LR_ind = -2 * np.log(L0 / L1)\n",
    "\n",
    "        p_value = 1 - chi2.cdf(LR_ind, df=1)\n",
    "        return LR_ind, p_value, (n00, n01, n10, n11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed58583",
   "metadata": {},
   "source": [
    "# Stress Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecbeaad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StressTester:\n",
    "    \"\"\"\n",
    "    Performs volatility and correlation stress testing using EWMA covariance.\n",
    "    - Volatility stress: scales the covariance matrix by k^2.\n",
    "    - Correlation stress: shifts correlations by delta_rho (capped at 1).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, portfolio: Portfolio):\n",
    "        self.portfolio = portfolio\n",
    "        self.returns_df = portfolio.get_returns_matrix()\n",
    "        self.exposures = portfolio.get_exposure_vector()\n",
    "        self.w_norm = self.exposures / np.sum(np.abs(self.exposures))\n",
    "\n",
    "    def base_covariance(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Compute the base EWMA covariance matrix.\n",
    "        Returns:\n",
    "            np.ndarray: covariance matrix.\n",
    "        \"\"\"\n",
    "        return ewma_covariance(self.returns_df, lambda_=ewma_lambda)\n",
    "\n",
    "    def base_portfolio_vol(self) -> float:\n",
    "        \"\"\"\n",
    "        Compute the base portfolio volatility from EWMA covariance.\n",
    "        Returns:\n",
    "            float: portfolio volatility.\n",
    "        \"\"\"\n",
    "        sigma = self.base_covariance()\n",
    "        sigma_p2 = self.w_norm @ sigma @ self.w_norm\n",
    "        return np.sqrt(sigma_p2)\n",
    "\n",
    "    def volatility_stress(self, k=k):\n",
    "        \"\"\"\n",
    "        Apply a volatility stress by scaling the covariance matrix:\n",
    "            Σ_stress = k^2 * Σ\n",
    "        This implies portfolio volatility scales by k.\n",
    "        Args:\n",
    "            k: volatility scaling factor.\n",
    "        Returns:\n",
    "            (sigma_stress, sigma_p_base, sigma_p_stress)\n",
    "        \"\"\"\n",
    "        sigma = self.base_covariance()\n",
    "        sigma_stress = (k ** 2) * sigma\n",
    "        sigma_p_base = self.base_portfolio_vol()\n",
    "        sigma_p_stress = k * sigma_p_base\n",
    "        return sigma_stress, sigma_p_base, sigma_p_stress\n",
    "\n",
    "    def correlation_stress(self, delta_rho=delta_rho):\n",
    "        \"\"\"\n",
    "        Apply a correlation stress by increasing all correlations by delta_rho,\n",
    "        capped at 1.0.\n",
    "\n",
    "        Steps:\n",
    "        1. Convert covariance to correlation matrix.\n",
    "        2. Add delta_rho to off-diagonal elements (capped at 1).\n",
    "        3. Convert back to covariance using original standard deviations.\n",
    "\n",
    "        Args:\n",
    "            delta_rho: correlation shift.\n",
    "\n",
    "        Returns:\n",
    "            (sigma_stress, sigma_p_base, sigma_p_stress)\n",
    "        \"\"\"\n",
    "        sigma = self.base_covariance()\n",
    "        stds = np.sqrt(np.diag(sigma))\n",
    "        D = np.diag(stds)\n",
    "\n",
    "        # Compute correlation matrix R = D^{-1} Σ D^{-1}\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            R = sigma / np.outer(stds, stds)\n",
    "            R = np.nan_to_num(R, nan=0.0)\n",
    "\n",
    "        # Apply correlation stress and cap at 1\n",
    "        R_stress = np.minimum(R + delta_rho, 1.0)\n",
    "\n",
    "        # Convert back to covariance: Σ_stress = D R_stress D\n",
    "        sigma_stress = D @ R_stress @ D\n",
    "\n",
    "        # Portfolio volatility under stressed correlations\n",
    "        sigma_p2_stress = self.w_norm @ sigma_stress @ self.w_norm\n",
    "        sigma_p_stress = np.sqrt(sigma_p2_stress)\n",
    "        sigma_p_base = self.base_portfolio_vol()\n",
    "\n",
    "        return sigma_stress, sigma_p_base, sigma_p_stress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e0742b",
   "metadata": {},
   "source": [
    "# Result Logging to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc3762c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_results_to_excel(results: dict, excel_path: str = kpi_filename):\n",
    "    \"\"\"\n",
    "    Append a single row of results to an Excel file.\n",
    "    - Index is the timestamp of computation.\n",
    "    - If the file exists, append; otherwise, create a new file.\n",
    "    Args:\n",
    "        results: dictionary of metric_name -> value\n",
    "        excel_path: path to the Excel file\n",
    "    \"\"\"\n",
    "    timestamp = pd.Timestamp(datetime.now())\n",
    "    row = pd.DataFrame(results, index=[timestamp])\n",
    "\n",
    "    if os.path.exists(excel_path):\n",
    "        existing = pd.read_excel(excel_path, index_col=0)\n",
    "        combined = pd.concat([existing, row])\n",
    "    else:\n",
    "        combined = row\n",
    "\n",
    "    combined.to_excel(excel_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929001bb",
   "metadata": {},
   "source": [
    "# Plotly Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19b8c677",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dashboard(loss_series: pd.Series,\n",
    "                    hist_var: float,\n",
    "                    hist_es: float,\n",
    "                    para_var: float,\n",
    "                    para_es: float,\n",
    "                    mc_losses: np.ndarray,\n",
    "                    mc_var: float,\n",
    "                    mc_es: float,\n",
    "                    exposure_weights: dict,\n",
    "                    metrics: dict,\n",
    "                    html_path: str = dashboard_name):\n",
    "    \"\"\"\n",
    "    Build and save the Plotly HTML dashboard.\n",
    "\n",
    "    Layout:\n",
    "    - Row 1 (3 columns): Histograms with VaR & ES lines\n",
    "        1. Historical VaR/ES\n",
    "        2. Parametric VaR/ES\n",
    "        3. Monte Carlo VaR/ES\n",
    "    - Row 2 (full width): Enhanced exposure weights plot\n",
    "        - Sorted ascending\n",
    "        - Category color-coding\n",
    "        - Top-5 exposures highlighted\n",
    "        - Cumulative Pareto curve\n",
    "    - Row 3 (full width): Metrics table\n",
    "\n",
    "    Args:\n",
    "        loss_series: portfolio loss series\n",
    "        hist_var, hist_es: historical VaR and ES\n",
    "        para_var, para_es: parametric VaR and ES\n",
    "        mc_losses, mc_var, mc_es: Monte Carlo losses, VaR, ES\n",
    "        exposure_weights: dict of instrument_name -> normalized weight\n",
    "        metrics: dict of metric_name -> value (for table)\n",
    "        html_path: output HTML file path\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a 3x3 grid of subplots with custom specs\n",
    "    fig = make_subplots(\n",
    "        rows=3, cols=3,\n",
    "        specs=[\n",
    "            [{\"type\": \"histogram\"}, {\"type\": \"histogram\"}, {\"type\": \"histogram\"}],\n",
    "            [{\"type\": \"bar\", \"colspan\": 3}, None, None],\n",
    "            [{\"type\": \"table\", \"colspan\": 3}, None, None],\n",
    "        ],\n",
    "        subplot_titles=(\"Historical VaR\", \"Parametric VaR\", \"Monte Carlo VaR\",\n",
    "                        \"Exposure Weights\", \"Key Metrics\")\n",
    "    )\n",
    "\n",
    "    # ---------------- Row 1: Historical VaR & ES ----------------\n",
    "    # Histogram of historical losses\n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            x=loss_series,\n",
    "            nbinsx=50,\n",
    "            name=\"Losses\",\n",
    "            marker_color=\"steelblue\",\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    # VaR line\n",
    "    fig.add_vline(x=hist_var, line=dict(color=\"red\", dash=\"dash\"), row=1, col=1)\n",
    "    fig.add_annotation(\n",
    "        x=hist_var, y=0.95, xref=\"x1\", yref=\"paper\",\n",
    "        text=f\"Hist VaR = {hist_var:.4f}\",\n",
    "        showarrow=True, arrowhead=2, ax=20, ay=-30,\n",
    "        font=dict(color=\"red\")\n",
    "    )\n",
    "    # ES line\n",
    "    fig.add_vline(x=hist_es, line=dict(color=\"purple\", dash=\"dot\"), row=1, col=1)\n",
    "    fig.add_annotation(\n",
    "        x=hist_es, y=0.85, xref=\"x1\", yref=\"paper\",\n",
    "        text=f\"Hist ES = {hist_es:.4f}\",\n",
    "        showarrow=True, arrowhead=2, ax=20, ay=-30,\n",
    "        font=dict(color=\"purple\")\n",
    "    )\n",
    "\n",
    "    # ---------------- Row 1: Parametric VaR & ES ----------------\n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            x=loss_series,\n",
    "            nbinsx=50,\n",
    "            name=\"Losses\",\n",
    "            marker_color=\"seagreen\",\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    fig.add_vline(x=para_var, line=dict(color=\"red\", dash=\"dash\"), row=1, col=2)\n",
    "    fig.add_annotation(\n",
    "        x=para_var, y=0.95, xref=\"x2\", yref=\"paper\",\n",
    "        text=f\"Param VaR = {para_var:.4f}\",\n",
    "        showarrow=True, arrowhead=2, ax=20, ay=-30,\n",
    "        font=dict(color=\"red\")\n",
    "    )\n",
    "    fig.add_vline(x=para_es, line=dict(color=\"purple\", dash=\"dot\"), row=1, col=2)\n",
    "    fig.add_annotation(\n",
    "        x=para_es, y=0.85, xref=\"x2\", yref=\"paper\",\n",
    "        text=f\"Param ES = {para_es:.4f}\",\n",
    "        showarrow=True, arrowhead=2, ax=20, ay=-30,\n",
    "        font=dict(color=\"purple\")\n",
    "    )\n",
    "\n",
    "    # Row 1: Monte Carlo VaR & ES\n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            x=mc_losses,\n",
    "            nbinsx=50,\n",
    "            name=\"Sim Losses\",\n",
    "            marker_color=\"darkorange\",\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=3\n",
    "    )\n",
    "    fig.add_vline(x=mc_var, line=dict(color=\"red\", dash=\"dash\"), row=1, col=3)\n",
    "    fig.add_annotation(\n",
    "        x=mc_var, y=0.95, xref=\"x3\", yref=\"paper\",\n",
    "        text=f\"MC VaR = {mc_var:.4f}\",\n",
    "        showarrow=True, arrowhead=2, ax=20, ay=-30,\n",
    "        font=dict(color=\"red\")\n",
    "    )\n",
    "    fig.add_vline(x=mc_es, line=dict(color=\"purple\", dash=\"dot\"), row=1, col=3)\n",
    "    fig.add_annotation(\n",
    "        x=mc_es, y=0.85, xref=\"x3\", yref=\"paper\",\n",
    "        text=f\"MC ES = {mc_es:.4f}\",\n",
    "        showarrow=True, arrowhead=2, ax=20, ay=-30,\n",
    "        font=dict(color=\"purple\")\n",
    "    )\n",
    "\n",
    "\n",
    "    # Row 2: Enhanced Exposure Weights Plot \n",
    "    # 1. Sort exposure weights ascending for better readability\n",
    "    sorted_items = sorted(exposure_weights.items(), key=lambda x: x[1])\n",
    "    inst_names = [item[0] for item in sorted_items]\n",
    "    inst_weights = [item[1] for item in sorted_items]\n",
    "\n",
    "    # 2. Category color-coding based on instrument name prefix\n",
    "    def category_color(name):\n",
    "        if name.startswith(\"MBL\"): return \"royalblue\"\n",
    "        if name.startswith(\"MPL\"): return \"seagreen\"\n",
    "        if name.startswith(\"Q_\"):  return \"darkorange\"\n",
    "        if name.startswith(\"M_\"):  return \"purple\"\n",
    "        if name.startswith(\"H_\"):  return \"brown\"\n",
    "        return \"grey\"\n",
    "\n",
    "    base_colors = [category_color(n) for n in inst_names]\n",
    "\n",
    "    # 3. Highlight top 5 exposures in crimson\n",
    "    if len(inst_weights) >= 5:\n",
    "        top5_threshold = sorted(inst_weights)[-5]\n",
    "    else:\n",
    "        # If fewer than 5 instruments, highlight the largest one\n",
    "        top5_threshold = sorted(inst_weights)[-1]\n",
    "\n",
    "    colors = [\n",
    "        \"crimson\" if w >= top5_threshold else base_colors[i]\n",
    "        for i, w in enumerate(inst_weights)\n",
    "    ]\n",
    "\n",
    "    # 4. Add bar chart (exposure weights)\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=inst_names,\n",
    "            y=inst_weights,\n",
    "            marker_color=colors,\n",
    "            hovertemplate=\"<b>%{x}</b><br>Weight: %{y:.6f}<extra></extra>\",\n",
    "            name=\"Exposure Weights\"\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "    # 5. Add cumulative exposure curve (Pareto-style)\n",
    "    cum_weights = np.cumsum(inst_weights)\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=inst_names,\n",
    "            y=cum_weights,\n",
    "            mode=\"lines+markers\",\n",
    "            name=\"Cumulative Weight\",\n",
    "            yaxis=\"y2\",  # secondary y-axis\n",
    "            line=dict(color=\"black\", width=2)\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "    # 6. Secondary y-axis for cumulative curve\n",
    "    fig.update_layout(\n",
    "        yaxis2=dict(\n",
    "            overlaying=\"y\",\n",
    "            side=\"right\",\n",
    "            title=\"Cumulative Weight\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # 7. Axis formatting for exposure plot\n",
    "    fig.update_xaxes(\n",
    "        tickangle=45,\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "    fig.update_yaxes(\n",
    "        title_text=\"Weight\",\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "    # ---------------- Row 3: Metrics Table ----------------\n",
    "    # Convert metrics dict into a 2-column table: Metric | Value\n",
    "    table_header = [\"Metric\", \"Value\"]\n",
    "    table_values = [\n",
    "        list(metrics.keys()),\n",
    "        [f\"{v:.2f}%\" if isinstance(v, (int, float)) else str(v) for v in metrics.values()]\n",
    "    ]\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Table(\n",
    "            header=dict(values=table_header, fill_color=\"lightgrey\", align=\"left\"),\n",
    "            cells=dict(values=table_values, align=\"left\")\n",
    "        ),\n",
    "        row=3, col=1\n",
    "    )\n",
    "\n",
    "    # ---------------- Layout and Hover Line ----------------\n",
    "    fig.update_layout(\n",
    "        title=\"Electricity Portfolio VaR & ES Dashboard\",\n",
    "        bargap=0.1,\n",
    "        template=\"plotly_white\",\n",
    "        height=1000,\n",
    "\n",
    "        # Vertical hover line (spike) across subplots\n",
    "        hovermode=\"x\",\n",
    "        spikedistance=-1,\n",
    "        xaxis=dict(showspikes=True, spikemode=\"across\", spikesnap=\"cursor\", spikethickness=1),\n",
    "        xaxis2=dict(showspikes=True, spikemode=\"across\", spikesnap=\"cursor\", spikethickness=1),\n",
    "        xaxis3=dict(showspikes=True, spikemode=\"across\", spikesnap=\"cursor\", spikethickness=1),\n",
    "        xaxis4=dict(showspikes=True, spikemode=\"across\", spikesnap=\"cursor\", spikethickness=1),\n",
    "    )\n",
    "\n",
    "    # Axis labels for histograms\n",
    "    fig.update_xaxes(title_text=\"Loss\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"Loss\", row=1, col=2)\n",
    "    fig.update_xaxes(title_text=\"Loss\", row=1, col=3)\n",
    "    fig.update_yaxes(title_text=\"Frequency\", row=1, col=1)\n",
    "\n",
    "    # Write dashboard to HTML file\n",
    "    fig.write_html(dashboard_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2111ee7f",
   "metadata": {},
   "source": [
    "# Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38dc87a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main orchestration function:\n",
    "\n",
    "    1. Load price and position data from Excel.\n",
    "    2. Build Instrument objects and the Portfolio.\n",
    "    3. Compute portfolio returns and losses.\n",
    "    4. Compute Historical, Parametric, and Monte Carlo VaR & ES.\n",
    "    5. Run backtests (Kupiec, Christoffersen).\n",
    "    6. Run stress tests (volatility and correlation).\n",
    "    7. Compute normalized exposure weights.\n",
    "    8. Log all metrics and weights to Excel.\n",
    "    9. Build and save the Plotly dashboard.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Load real price data (wide format: Date index, product columns)\n",
    "    price_df = pd.read_excel(prices_xlsx, index_col=0, parse_dates=True)\n",
    "\n",
    "    # 2. Load positions (MWh and Sensitivity) from Excel\n",
    "    pos_df = pd.read_excel(positions_xlsx)\n",
    "    # Expected columns: Product, MWh, Sensitivity\n",
    "    mwh_map = dict(zip(pos_df[\"Product\"], pos_df[\"MWh\"]))\n",
    "    sens_map = dict(zip(pos_df[\"Product\"], pos_df[\"Sensitivity\"]))\n",
    "\n",
    "    # 3. Build instruments from real data\n",
    "    instruments = []\n",
    "    for col in price_df.columns:\n",
    "        prices = price_df[col].dropna()\n",
    "        # Only create instruments for which we have a position\n",
    "        if col not in mwh_map:\n",
    "            continue\n",
    "        mwh = float(mwh_map[col])\n",
    "        sensitivity = float(sens_map.get(col, 1.0))  # default sensitivity = 1.0\n",
    "        instruments.append(Instrument(name=col, prices=prices, mwh=mwh, price_sensitivity=sensitivity))\n",
    "\n",
    "    if not instruments:\n",
    "        raise ValueError(\"No instruments created. Check that product names in prices.xlsx match positions.xlsx.\")\n",
    "\n",
    "    # 4. Create portfolio from instruments\n",
    "    portfolio = Portfolio(instruments=instruments)\n",
    "\n",
    "    # 5. Portfolio returns and losses (used for historical VaR/ES and backtesting)\n",
    "    port_returns = portfolio.portfolio_return_series()\n",
    "    port_losses = portfolio.portfolio_loss_series()\n",
    "\n",
    "    # 6. VaR & ES calculations\n",
    "    var_calc = VaRCalculator(portfolio=portfolio, alpha=alpha)\n",
    "\n",
    "    # Historical VaR & ES\n",
    "    hist_var = var_calc.historical_var()\n",
    "    hist_es = var_calc.historical_es()\n",
    "\n",
    "    # Parametric VaR & ES (EWMA)\n",
    "    mu_vec, sigma_mat, mu_p, sigma_p, w_norm = var_calc.parametric_inputs()\n",
    "    para_var = var_calc.parametric_var()\n",
    "    para_es = var_calc.parametric_es()\n",
    "\n",
    "    # Monte Carlo VaR & ES (EWMA)\n",
    "    mc_var, mc_es, mc_losses = var_calc.monte_carlo_var_es(n_mc)\n",
    "\n",
    "    # 7. Backtesting using Historical VaR\n",
    "    var_series_hist = pd.Series(hist_var, index=port_losses.index, name=\"VaR_Hist\")\n",
    "    backtester_hist = Backtester(loss_series=port_losses, var_series=var_series_hist, alpha=alpha)\n",
    "    kupiec_LR, kupiec_p, N_exc, T_obs = backtester_hist.kupiec_pof_test()\n",
    "    christ_LR, christ_p, trans_counts = backtester_hist.christoffersen_independence_test()\n",
    "\n",
    "    # 8. Stress testing (volatility and correlation)\n",
    "    stress_tester = StressTester(portfolio=portfolio)\n",
    "    sigma_stress_vol, sigma_p_base_vol, sigma_p_stress_vol = stress_tester.volatility_stress(k=2.0)\n",
    "    sigma_stress_corr, sigma_p_base_corr, sigma_p_stress_corr = stress_tester.correlation_stress(delta_rho=0.2)\n",
    "\n",
    "    # 9. Normalized exposure weights (for Excel logging + dashboard)\n",
    "    exposures = portfolio.get_exposure_vector()\n",
    "    w_norm = exposures / np.sum(np.abs(exposures))\n",
    "    exposure_weights = {inst.name: float(w * 100) for inst, w in zip(instruments, w_norm)}\n",
    "\n",
    "    # 10. Collect metrics for Excel and table\n",
    "    results = {\n",
    "        \"Portfolio_Mean\": mu_p *100,\n",
    "        \"Portfolio_Volatility\": sigma_p *100,\n",
    "        \"Hist_VaR\": hist_var *100,\n",
    "        \"Hist_ES\": hist_es *100,\n",
    "        \"Para_VaR\": para_var *100,\n",
    "        \"Para_ES\": para_es *100,\n",
    "        \"MC_VaR\": mc_var *100,\n",
    "        \"MC_ES\": mc_es *100,\n",
    "        \"Kupiec_LR\": kupiec_LR *100,\n",
    "        \"Kupiec_p_value\": kupiec_p,\n",
    "        \"Christoffersen_LR\": christ_LR,\n",
    "        \"Christoffersen_p_value\": christ_p,\n",
    "        \"N_exceedances\": N_exc ,\n",
    "        \"T_observations\": int(T_obs),\n",
    "        \"Base_Portfolio_Volatility\": sigma_p_base_vol *100,\n",
    "        \"Vol_Stress_Portfolio_Volatility\": sigma_p_stress_vol *100,\n",
    "        \"Corr_Stress_Base_Volatility\": sigma_p_base_corr *100,\n",
    "        \"Corr_Stress_Portfolio_Volatility\": sigma_p_stress_corr *100,\n",
    "    }\n",
    "\n",
    "    # Add exposure weights to Excel metrics (one column per instrument)\n",
    "    for name, w in exposure_weights.items():\n",
    "        results[f\"{name}_weight\"] = w\n",
    "\n",
    "    # Append results to Excel log\n",
    "    append_results_to_excel(results, kpi_filename)\n",
    "\n",
    "    # 11. Build and save the dashboard\n",
    "    build_dashboard(\n",
    "        loss_series=port_losses,\n",
    "        hist_var=hist_var,\n",
    "        hist_es=hist_es,\n",
    "        para_var=para_var,\n",
    "        para_es=para_es,\n",
    "        mc_losses=mc_losses,\n",
    "        mc_var=mc_var,\n",
    "        mc_es=mc_es,\n",
    "        exposure_weights=exposure_weights,\n",
    "        metrics=results,\n",
    "        html_path=dashboard_name\n",
    "    )\n",
    "\n",
    "    print(\"Computation complete.\")\n",
    "    print(f\"Dashboard saved to: {dashboard_name}\")\n",
    "    print(f\"Results appended to: {kpi_filename}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d912979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation complete.\n",
      "Dashboard saved to: electricity_risk_report.html\n",
      "Results appended to: KPI.xlsx\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "14_pred_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
